# =============================================================================
# v0 Strategy Engine Pro - AI Model Configuration Template
# =============================================================================
# This file contains comprehensive AI/LLM model configurations
# Copy relevant sections to your main .env file
# Get API keys from respective provider websites

# =============================================================================
# OPENAI (GPT-4, GPT-4 Turbo, GPT-3.5)
# =============================================================================
# Provider: https://platform.openai.com/
# Get API key: https://platform.openai.com/api-keys
# Models: gpt-4, gpt-4-turbo-preview, gpt-3.5-turbo, gpt-4-vision
OPENAI_API_KEY=sk-your_openai_api_key
OPENAI_MODEL=gpt-4-turbo-preview
OPENAI_MAX_TOKENS=4096
OPENAI_TEMPERATURE=0.7
OPENAI_TOP_P=1.0
OPENAI_FREQUENCY_PENALTY=0.0
OPENAI_PRESENCE_PENALTY=0.0

# =============================================================================
# ANTHROPIC (Claude 3 Family)
# =============================================================================
# Provider: https://www.anthropic.com/
# Get API key: https://console.anthropic.com/
# Models: claude-3-opus, claude-3-sonnet, claude-3-haiku
ANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key
ANTHROPIC_MODEL=claude-3-opus-20240229
ANTHROPIC_MAX_TOKENS=4096
ANTHROPIC_TEMPERATURE=0.7
ANTHROPIC_TOP_P=1.0
ANTHROPIC_TOP_K=40

# =============================================================================
# GOOGLE AI (Gemini Family)
# =============================================================================
# Provider: https://ai.google.dev/
# Get API key: https://makersuite.google.com/app/apikey
# Models: gemini-1.5-pro, gemini-1.5-flash, gemini-pro-vision
GOOGLE_API_KEY=your_google_ai_api_key
GOOGLE_MODEL=gemini-1.5-pro
GOOGLE_MAX_TOKENS=8192
GOOGLE_TEMPERATURE=0.7
GOOGLE_TOP_P=0.95
GOOGLE_TOP_K=40

# =============================================================================
# xAI GROK (Free Tier + Paid API)
# =============================================================================
# Provider: https://x.ai/
# Get API key: https://console.x.ai/
# Free tier: Limited requests/day, testing and development
# Paid tier: Higher rate limits, production usage
# Models: grok-beta, grok-vision-beta
XAI_GROK_API_KEY=your_xai_grok_api_key
XAI_GROK_API_TIER=free  # Options: free, paid
XAI_GROK_MODEL=grok-beta
XAI_GROK_MAX_TOKENS=4096
XAI_GROK_TEMPERATURE=0.7
XAI_GROK_BASE_URL=https://api.x.ai/v1

# =============================================================================
# PERPLEXITY AI (Sonar Models - Real-time Web Search)
# =============================================================================
# Provider: https://www.perplexity.ai/
# Get API key: https://www.perplexity.ai/settings/api
# Models: sonar-small-online, sonar-medium-online, sonar-medium-chat
# Best for: Real-time market news, sentiment analysis
PERPLEXITY_API_KEY=your_perplexity_api_key
PERPLEXITY_MODEL=sonar-medium-online
PERPLEXITY_MAX_TOKENS=4096
PERPLEXITY_TEMPERATURE=0.2  # Lower for factual queries
PERPLEXITY_BASE_URL=https://api.perplexity.ai

# =============================================================================
# COHERE (Command Models)
# =============================================================================
# Provider: https://cohere.ai/
# Get API key: https://dashboard.cohere.com/api-keys
# Models: command, command-light, command-nightly, command-r, command-r-plus
COHERE_API_KEY=your_cohere_api_key
COHERE_MODEL=command
COHERE_MAX_TOKENS=4096
COHERE_TEMPERATURE=0.7
COHERE_K=0
COHERE_P=0.75

# =============================================================================
# MISTRAL AI (Open Models)
# =============================================================================
# Provider: https://mistral.ai/
# Get API key: https://console.mistral.ai/
# Models: mistral-tiny, mistral-small, mistral-medium, mistral-large
# Also: mixtral-8x7b-32768 (via Mistral API)
MISTRAL_API_KEY=your_mistral_api_key
MISTRAL_MODEL=mistral-medium
MISTRAL_MAX_TOKENS=4096
MISTRAL_TEMPERATURE=0.7
MISTRAL_TOP_P=1.0

# =============================================================================
# HUGGING FACE (Inference API)
# =============================================================================
# Provider: https://huggingface.co/
# Get API token: https://huggingface.co/settings/tokens
# Access 100,000+ open-source models
# Popular: mistralai/Mistral-7B-Instruct-v0.2, meta-llama/Llama-2-70b-chat-hf
HUGGINGFACE_API_KEY=your_huggingface_api_token
HUGGINGFACE_MODEL=mistralai/Mistral-7B-Instruct-v0.2
HUGGINGFACE_MAX_TOKENS=2048
HUGGINGFACE_TEMPERATURE=0.7
HUGGINGFACE_BASE_URL=https://api-inference.huggingface.co/models

# =============================================================================
# REPLICATE (Cloud Model Hosting)
# =============================================================================
# Provider: https://replicate.com/
# Get API token: https://replicate.com/account/api-tokens
# Popular models: meta/llama-2-70b-chat, stability-ai/sdxl
REPLICATE_API_KEY=your_replicate_api_token
REPLICATE_MODEL=meta/llama-2-70b-chat:latest
REPLICATE_MAX_TOKENS=4096
REPLICATE_TEMPERATURE=0.7

# =============================================================================
# OPENROUTER (Multi-Model Gateway)
# =============================================================================
# Provider: https://openrouter.ai/
# Get API key: https://openrouter.ai/keys
# Access multiple providers via unified API: OpenAI, Anthropic, Google, Meta
# Pay-as-you-go pricing across all models
OPENROUTER_API_KEY=your_openrouter_api_key
OPENROUTER_MODEL=anthropic/claude-3-opus
OPENROUTER_MAX_TOKENS=4096
OPENROUTER_TEMPERATURE=0.7
OPENROUTER_BASE_URL=https://openrouter.ai/api/v1

# =============================================================================
# TOGETHER AI (Open-Source Models)
# =============================================================================
# Provider: https://www.together.ai/
# Get API key: https://api.together.xyz/settings/api-keys
# Models: Llama 2, Mistral, Code Llama, and more
TOGETHER_API_KEY=your_together_api_key
TOGETHER_MODEL=togethercomputer/llama-2-70b-chat
TOGETHER_MAX_TOKENS=4096
TOGETHER_TEMPERATURE=0.7
TOGETHER_BASE_URL=https://api.together.xyz/v1

# =============================================================================
# GROQ (Ultra-Fast Inference)
# =============================================================================
# Provider: https://groq.com/
# Get API key: https://console.groq.com/keys
# Models: llama2-70b-4096, mixtral-8x7b-32768, gemma-7b-it
# Ultra-fast inference (500+ tokens/sec)
GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=mixtral-8x7b-32768
GROQ_MAX_TOKENS=32768
GROQ_TEMPERATURE=0.7
GROQ_BASE_URL=https://api.groq.com/openai/v1

# =============================================================================
# AI MODEL ORCHESTRATION & ROUTING
# =============================================================================

# Primary model for general tasks
AI_PRIMARY_MODEL=openai

# Fallback model if primary fails
AI_FALLBACK_MODEL=anthropic

# Task-specific model assignments
# Market analysis: Comprehensive market data interpretation
AI_MARKET_ANALYSIS_MODEL=openai

# Sentiment analysis: Real-time news and social sentiment
AI_SENTIMENT_MODEL=perplexity  # Best for real-time web data

# Signal generation: Trading signal recommendations
AI_SIGNAL_MODEL=anthropic  # Claude excels at reasoning

# Risk assessment: Risk evaluation and position sizing
AI_RISK_MODEL=anthropic

# Code generation: Strategy development and debugging
AI_CODE_MODEL=openai  # GPT-4 for code tasks

# Fast inference tasks: Quick decisions, real-time analysis
AI_FAST_MODEL=groq  # Ultra-fast inference

# =============================================================================
# ENSEMBLE CONFIGURATION (Multi-Model Consensus)
# =============================================================================

# Enable ensemble mode (use multiple models for consensus)
AI_ENSEMBLE_ENABLED=false

# Models to include in ensemble (comma-separated)
AI_ENSEMBLE_MODELS=openai,anthropic,google

# Voting mechanism
# - majority: Simple majority vote
# - weighted: Confidence-weighted voting
# - unanimous: All models must agree
AI_ENSEMBLE_VOTING=majority

# Confidence threshold (0.0-1.0)
AI_ENSEMBLE_MIN_CONFIDENCE=0.7

# =============================================================================
# RATE LIMITING & RETRY LOGIC
# =============================================================================

# Maximum requests per minute (applies to all providers)
AI_MAX_REQUESTS_PER_MINUTE=60

# Retry configuration
AI_RETRY_ATTEMPTS=3
AI_RETRY_DELAY=2  # seconds
AI_RETRY_EXPONENTIAL_BACKOFF=true

# Timeout settings (seconds)
AI_REQUEST_TIMEOUT=30
AI_STREAM_TIMEOUT=60

# =============================================================================
# COST OPTIMIZATION
# =============================================================================

# Enable cost tracking
AI_TRACK_COSTS=true

# Daily spending limit (USD)
AI_DAILY_SPENDING_LIMIT=50.0

# Cost-aware model selection (switch to cheaper models when approaching limit)
AI_COST_AWARE_ROUTING=false

# Model cost tiers (used for automatic downgrading)
AI_COST_TIER_HIGH=openai,anthropic
AI_COST_TIER_MEDIUM=google,mistral,cohere
AI_COST_TIER_LOW=groq,together,huggingface

# =============================================================================
# CACHING & OPTIMIZATION
# =============================================================================

# Enable response caching (reduces API calls)
AI_CACHE_ENABLED=true
AI_CACHE_TTL=3600  # seconds (1 hour)
AI_CACHE_MAX_SIZE=1000  # entries

# Semantic cache (cache similar prompts)
AI_SEMANTIC_CACHE_ENABLED=false
AI_SEMANTIC_SIMILARITY_THRESHOLD=0.95

# =============================================================================
# MONITORING & LOGGING
# =============================================================================

# Log all AI requests/responses
AI_LOG_REQUESTS=true
AI_LOG_RESPONSES=false  # Set true for debugging (can be verbose)

# Performance monitoring
AI_TRACK_LATENCY=true
AI_TRACK_TOKEN_USAGE=true

# Alert on failures
AI_ALERT_ON_FAILURE=true
AI_FAILURE_ALERT_THRESHOLD=5  # Alert after 5 consecutive failures